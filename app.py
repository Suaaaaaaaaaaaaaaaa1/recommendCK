import streamlit as st
import pandas as pd
import pickle
import os
import ast
import gdown
import random 
from surprise import SVD

# --- 1. ƒê·ªãnh nghƒ©a T√™n t·ªáp v√† File IDs ---
MODEL_FILE_PATH = 'svd_model.pkl' 
METADATA_FILE_PATH = 'recipes_metadata.csv' 

# !!! ID C·ª¶A B·∫†N T·ª™ L·∫¶N TR∆Ø·ªöC !!!
MODEL_FILE_ID = '1mSWLAjm2Ho6Aox61PrIQJUgNyJObKSbu' 
METADATA_FILE_ID = '1jCm7OruZnwkkd5GRU42dycNcQdGOKNRv'

# --- 2. H√†m T·∫£i t·ªáp chung ---
def download_file_from_gdrive(file_id, dest_path):
    if not os.path.exists(dest_path):
        with st.spinner(f"ƒêang t·∫£i t√†i nguy√™n: {dest_path} (l·∫ßn ƒë·∫ßu ti√™n)..."):
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, dest_path, quiet=False)
    return dest_path

# --- 3. H√†m T·∫£i Model v√† D·ªØ li·ªáu ---
@st.cache_resource
def load_model(file_id, dest_path):
    # D√πng cache_resource ƒë·ªÉ t·∫£i model 1 L·∫¶N DUY NH·∫§T
    try:
        model_path = download_file_from_gdrive(file_id, dest_path)
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i m√¥ h√¨nh: {e}")
        return None

@st.cache_data
def load_metadata(file_id, dest_path):
    # D√πng cache_data ƒë·ªÉ t·∫£i metadata 1 L·∫¶N DUY NH·∫§T
    try:
        metadata_path = download_file_from_gdrive(file_id, dest_path)
        df = pd.read_csv(metadata_path)
        return df
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i metadata: {e}")
        return pd.DataFrame()

# --- 4. H√†m l·∫•y h√¨nh ·∫£nh (Kh√¥ng ƒë·ªïi) ---
def get_first_image_url(images_str):
    placeholder_image = "https://cdn.freelogovectors.net/wp-content/uploads/2022/10/foodcom-logo-freelogovectors.net_-400x144.png"
    if not isinstance(images_str, str) or pd.isna(images_str):
        return placeholder_image
    try:
        evaluated_data = ast.literal_eval(images_str)
        if isinstance(evaluated_data, list):
            if len(evaluated_data) > 0:
                return evaluated_data[0]
            else:
                return placeholder_image
        if isinstance(evaluated_data, str):
            if evaluated_data.startswith('http'):
                return evaluated_data
            else:
                return placeholder_image
    except (ValueError, SyntaxError):
        if images_str.startswith('http'):
            return images_str
    return placeholder_image

# --- 5. H√ÄM T√çNH TO√ÅN (ƒê√É B·ªé SAMPLE) ---
# H√†m n√†y kh√¥ng c·∫ßn cache n·ªØa v√¨ n√≥ ƒë∆∞·ª£c g·ªçi b·∫±ng n√∫t b·∫•m
def get_all_predictions(user_id):
    """
    T√≠nh to√°n d·ª± ƒëo√°n tr√™n TO√ÄN B·ªò danh s√°ch m√≥n ƒÉn.
    """
    
    # 1. L·∫•y TO√ÄN B·ªò ID (d√πng bi·∫øn to√†n c·ª•c)
    all_ids = all_recipe_ids_tuple

    # 2. D·ª± ƒëo√°n tr√™n TO√ÄN B·ªò (d√πng bi·∫øn to√†n c·ª•c)
    predictions = []
    for recipe_id in all_ids:
        pred = model.predict(uid=user_id, iid=recipe_id)
        predictions.append((recipe_id, pred.est))
        
    # 3. S·∫Øp x·∫øp danh s√°ch
    predictions.sort(key=lambda x: x[1], reverse=True)
    return predictions

# --- 6. X√¢y d·ª±ng giao di·ªán Streamlit ---
st.set_page_config(layout="wide")
st.title("H·ªá th·ªëng G·ª£i √Ω M√≥n ƒÉn üç≤ üç≥ üç∞")

# --- N·∫†P C√ÅC BI·∫æN "TO√ÄN C·ª§C" ---
model = load_model(MODEL_FILE_ID, MODEL_FILE_PATH)
metadata_df = load_metadata(METADATA_FILE_ID, METADATA_FILE_PATH)

if model and not metadata_df.empty:
    st.header("T√¨m m√≥n ƒÉn cho b·∫°n")
    
    # --- S·ª¨A L·ªñI TYPO (g√µ nh·∫ßm) T·∫†I ƒê√ÇY ---
    # T√™n c·ªôt ph·∫£i l√† 'Recipe_ID' (c√≥ d·∫•u g·∫°ch d∆∞·ªõi)
    all_recipe_ids_tuple = tuple(metadata_df['RecipeId'].unique())
    metadata_df = metadata_df.set_index('RecipeId')
    
    # --- WIDGETS ---
    user_id_input = st.number_input(
        "Nh·∫≠p User ID c·ªßa b·∫°n:", 
        min_value=1, 
        value=1535,
        step=1,
        help="H√£y nh·∫≠p m·ªôt User ID (v√≠ d·ª•: 1535, 2046, 5201...)"
    )
    
    num_recs = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω:", min_value=5, max_value=20, value=10)

    # --- TH√äM L·∫†I N√öT B·∫§M ---
    if st.button("T√¨m ki·∫øm g·ª£i √Ω"):
        with st.spinner("ƒêang t√≠nh to√°n g·ª£i √Ω (tr√™n to√†n b·ªô d·ªØ li·ªáu)..."):
            # Ch·∫°y h√†m t√≠nh to√°n M·ªöI (kh√¥ng sample)
            all_preds = get_all_predictions(user_id_input) 
            # L∆ØU k·∫øt qu·∫£ v√†o session_state
            st.session_state['all_predictions'] = all_preds
    
    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ T·ª™ SESSION_STATE ---
    # Lu√¥n ki·ªÉm tra xem 'all_predictions' ƒë√£ t·ªìn t·∫°i ch∆∞a
    if 'all_predictions' in st.session_state:
        # L·∫•y Top N t·ª´ k·∫øt qu·∫£ ƒë√£ l∆∞u
        all_preds = st.session_state['all_predictions']
        top_n_preds = all_preds[:num_recs]
        
        top_n_ids = [recipe_id for recipe_id, score in top_n_preds]
        
        # Tra c·ª©u metadata
        valid_top_n_ids = [idx for idx in top_n_ids if idx in metadata_df.index]
        if valid_top_n_ids:
            recs_df = metadata_df.loc[valid_top_n_ids].copy()
            
            st.subheader(f"K·∫øt qu·∫£ g·ª£i √Ω:")
            
            cols = st.columns(2)
            col_idx = 0
            
            for index, row in recs_df.iterrows():
                with cols[col_idx]:
                    image_url = get_first_image_url(row['Images'])
                    st.image(image_url, caption=f"Recipe ID: {row.name}", use_container_width=True)
                    st.subheader(row['Name'])
                    if 'Description' in row and pd.notna(row['Description']):
                         st.markdown(f"**M√¥ t·∫£:** {row['Description'][:150]}...")
                    st.divider()
                
                col_idx = (col_idx + 1) % 2
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y g·ª£i √Ω n√†o.")
else:
    st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh ho·∫∑c d·ªØ li·ªáu t·ª´ Google Drive. Vui l√≤ng ki·ªÉm tra l·∫°i File IDs.")
