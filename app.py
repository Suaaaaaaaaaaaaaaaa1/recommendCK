import streamlit as st
import pandas as pd
import pickle
import os
import ast
import gdown
import random 
import re  # Th∆∞ vi·ªán cho t√¨m ki·∫øm
from surprise import SVD

# --- 1. ƒê·ªãnh nghƒ©a T√™n t·ªáp v√† File IDs ---
MODEL_FILE_PATH = 'svd_model.pkl' 
METADATA_FILE_PATH = 'recipes_metadata.csv' 

# !!! ID C·ª¶A B·∫†N T·ª™ L·∫¶N TR∆Ø·ªöC !!!
MODEL_FILE_ID = '1mSWLAjm2Ho6Aox61PrIQJUgNyJObKSbu' 
METADATA_FILE_ID = '1jCm7OruZnwkkd5GRU42dycNcQdGOKNRv'

# --- 2. H√†m T·∫£i t·ªáp chung ---
def download_file_from_gdrive(file_id, dest_path):
    if not os.path.exists(dest_path):
        with st.spinner(f"ƒêang t·∫£i t√†i nguy√™n: {dest_path} (l·∫ßn ƒë·∫ßu ti√™n)..."):
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, dest_path, quiet=False)
    return dest_path

# --- 3. H√†m T·∫£i Model v√† D·ªØ li·ªáu ---
@st.cache_resource
def load_model(file_id, dest_path):
    try:
        model_path = download_file_from_gdrive(file_id, dest_path)
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i m√¥ h√¨nh: {e}")
        return None

@st.cache_data
def load_metadata(file_id, dest_path):
    try:
        metadata_path = download_file_from_gdrive(file_id, dest_path)
        df = pd.read_csv(metadata_path)
        return df
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i metadata: {e}")
        return pd.DataFrame()

# --- 4. H√†m l·∫•y h√¨nh ·∫£nh (Kh√¥ng ƒë·ªïi) ---
def get_first_image_url(images_str):
    placeholder_image = "https://cdn.freelogovectors.net/wp-content/uploads/2022/10/foodcom-logo-freelogovectors.net_-400x144.png"
    if not isinstance(images_str, str) or pd.isna(images_str):
        return placeholder_image
    match = re.search(r'"(https://[^"]+)"', images_str)
    if match:
        return match.group(1)
    else:
        if images_str.startswith('http'):
            return images_str
    return placeholder_image

# --- 5. H√ÄM T√çNH TO√ÅN (Cho Tab 2) ---
def get_all_predictions(user_id):
    all_ids = all_recipe_ids_tuple
    predictions = []
    for recipe_id in all_ids:
        pred = model.predict(uid=user_id, iid=recipe_id)
        predictions.append((recipe_id, pred.est))
    predictions.sort(key=lambda x: x[1], reverse=True)
    return predictions

# --- 6. H√ÄM X√ÇY D·ª∞NG TAB 1 (Duy·ªát m√≥n ƒÉn) ---
def build_browse_tab(metadata_df):
    
    # 6.1. X·ª≠ l√Ω hi·ªÉn th·ªã chi ti·∫øt (Modal/Dialog)
    if 'detail_recipe_id' in st.session_state and st.session_state['detail_recipe_id'] is not None:
        recipe_id = st.session_state['detail_recipe_id']
        
        # <<< S·ª¨A L·ªñI T·∫†I ƒê√ÇY
        recipe_data = metadata_df[metadata_df['RecipeId'] == recipe_id].iloc[0]
        
        with st.dialog(f"Chi ti·∫øt m√≥n ƒÉn: {recipe_data['Name']}"):
            st.image(get_first_image_url(recipe_data['Images']), use_container_width=True)
            st.subheader(recipe_data['Name'])
            st.dataframe(recipe_data) 
            if st.button("ƒê√≥ng", key="close_dialog"):
                st.session_state['detail_recipe_id'] = None
                st.rerun() 

    # 6.2. B·ªô l·ªçc
    with st.expander("T√¨m ki·∫øm v√† L·ªçc", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            search_name = st.text_input("T√¨m theo T√™n m√≥n ƒÉn")
            search_id = st.number_input("T√¨m theo ID m√≥n ƒÉn", value=None, step=1, placeholder="Nh·∫≠p ID...")
        
        with col2:
            categories = ["T·∫•t c·∫£"] + sorted(list(metadata_df['RecipeCategory'].dropna().unique()))
            search_category = st.selectbox("L·ªçc theo Danh m·ª•c", options=categories)
            search_ingredients = st.text_input("L·ªçc theo Nguy√™n li·ªáu (ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y)")

    # 6.3. √Åp d·ª•ng b·ªô l·ªçc
    filtered_df = metadata_df.copy()

    if search_name:
        filtered_df = filtered_df[filtered_df['Name'].str.contains(search_name, case=False, na=False)]
    
    if search_id is not None:
        # <<< S·ª¨A L·ªñI T·∫†I ƒê√ÇY
        filtered_df = filtered_df[filtered_df['RecipeId'] == search_id]
        
    if search_category != "T·∫•t c·∫£":
        filtered_df = filtered_df[filtered_df['RecipeCategory'] == search_category]

    if search_ingredients:
        ingredients_list = [ing.strip() for ing in search_ingredients.split(',') if ing.strip()]
        for ing in ingredients_list:
            filtered_df = filtered_df[filtered_df['RecipeIngredientParts'].str.contains(ing, case=False, na=False)]

    # 6.4. Ph√¢n trang (Pagination)
    total_items = len(filtered_df)
    st.write(f"T√¨m th·∫•y **{total_items}** m√≥n ƒÉn ph√π h·ª£p.")
    
    if total_items > 0:
        ITEMS_PER_PAGE = 10
        total_pages = max(1, (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE)
        
        page_col1, page_col2 = st.columns([1, 1])
        with page_col1:
            page_number = st.number_input("Trang", min_value=1, max_value=total_pages, value=1, step=1)
        with page_col2:
            st.write(f"T·ªïng s·ªë trang: {total_pages}")

        start_idx = (page_number - 1) * ITEMS_PER_PAGE
        end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)
        
        items_to_display = filtered_df.iloc[start_idx:end_idx]

        # 6.5. V√≤ng l·∫∑p hi·ªÉn th·ªã
        cols = st.columns(2)
        col_idx = 0
        
        for index, row in items_to_display.iterrows():
            with cols[col_idx]:
                # <<< S·ª¨A L·ªñI T·∫†I ƒê√ÇY
                image_url = get_first_image_url(row['Images'])
                st.image(image_url, caption=f"Recipe ID: {row['RecipeId']}", use_container_width=True)
                st.subheader(row['Name'])
                
                # <<< S·ª¨A L·ªñI T·∫†I ƒê√ÇY
                if st.button("Xem chi ti·∫øt", key=f"detail_{row['RecipeId']}"):
                    st.session_state['detail_recipe_id'] = row['RecipeId']
                    st.rerun() 
                
                st.divider()
            
            col_idx = (col_idx + 1) % 2

# --- 7. H√ÄM X√ÇY D·ª∞NG TAB 2 (G·ª£i √Ω) ---
def build_predict_tab(metadata_df_indexed):
    
    st.header("T√¨m m√≥n ƒÉn cho b·∫°n")
    
    # --- WIDGETS ---
    user_id_input = st.number_input(
        "Nh·∫≠p User ID c·ªßa b·∫°n:", 
        min_value=1, 
        value=1535,
        step=1,
        help="H√£y nh·∫≠p m·ªôt User ID (v√≠ d·ª•: 1535, 2046, 5201...)"
    )
    
    num_recs = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω:", min_value=5, max_value=20, value=10)

    # --- N√öT B·∫§M ---
    if st.button("T√¨m ki·∫øm g·ª£i √Ω"):
        with st.spinner("ƒêang t√≠nh to√°n g·ª£i √Ω (tr√™n to√†n b·ªô d·ªØ li·ªáu)..."):
            all_preds = get_all_predictions(user_id_input) 
            st.session_state['all_predictions'] = all_preds
    
    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ T·ª™ SESSION_STATE ---
    if 'all_predictions' in st.session_state:
        all_preds = st.session_state['all_predictions']
        top_n_preds = all_preds[:num_recs]
        
        top_n_ids = [recipe_id for recipe_id, score in top_n_preds]
        
        valid_top_n_ids = [idx for idx in top_n_ids if idx in metadata_df_indexed.index]
        if valid_top_n_ids:
            recs_df = metadata_df_indexed.loc[valid_top_n_ids].copy()
            
            st.subheader(f"K·∫øt qu·∫£ g·ª£i √Ω:")
            
            cols = st.columns(2)
            col_idx = 0
            
            for index, row in recs_df.iterrows():
                with cols[col_idx]:
                    image_url = get_first_image_url(row['Images'])
                    st.image(image_url, caption=f"Recipe ID: {row.name}", use_container_width=True)
                    st.subheader(row['Name'])
                    if 'Description' in row and pd.notna(row['Description']):
                         st.markdown(f"**M√¥ t·∫£:** {row['Description'][:150]}...")
                    st.divider()
                
                col_idx = (col_idx + 1) % 2
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y g·ª£i √Ω n√†o.")

# --- 8. CH·∫†Y ·ª®NG D·ª§NG CH√çNH ---
st.set_page_config(layout="wide")
st.title("H·ªá th·ªëng G·ª£i √Ω M√≥n ƒÉn üç≤ üç≥ üç∞")

model = load_model(MODEL_FILE_ID, MODEL_FILE_PATH)
metadata_df = load_metadata(METADATA_FILE_ID, METADATA_FILE_PATH)

if model and not metadata_df.empty:
    
    # Kh·ªüi t·∫°o session state
    if 'detail_recipe_id' not in st.session_state:
        st.session_state['detail_recipe_id'] = None
    if 'all_predictions' not in st.session_state:
        st.session_state['all_predictions'] = None
    
    # <<< S·ª¨A L·ªñI T·∫†I ƒê√ÇY
    # Bi·∫øn to√†n c·ª•c cho h√†m d·ª± ƒëo√°n
    all_recipe_ids_tuple = tuple(metadata_df['RecipeId'].unique())
    # DataFrame ƒë√£ index cho Tab 2
    metadata_df_indexed = metadata_df.set_index('RecipeId')
    
    # T·∫°o c√°c tab
    tab1, tab2 = st.tabs(["Duy·ªát M√≥n ƒÇn", "G·ª£i √ù Cho B·∫°n"])

    with tab1:
        # Tab 1 d√πng metadata_df (ch∆∞a index) ƒë·ªÉ l·ªçc
        build_browse_tab(metadata_df)
        
    with tab2:
        # Tab 2 d√πng metadata_df_indexed ƒë·ªÉ tra c·ª©u
        build_predict_tab(metadata_df_indexed)
        
else:
    st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh ho·∫∑c d·ªØ li·ªáu t·ª´ Google Drive. Vui l√≤ng ki·ªÉm tra l·∫°i File IDs.")
