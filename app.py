import streamlit as st
import pandas as pd
import pickle
import os
import ast
import gdown
import random # <-- TH√äM TH∆Ø VI·ªÜN N√ÄY
from surprise import SVD

# --- 1. ƒê·ªãnh nghƒ©a T√™n t·ªáp v√† File IDs ---
MODEL_FILE_PATH = 'svd_model.pkl' 
METADATA_FILE_PATH = 'recipes_metadata.csv' 

# !!! THAY TH·∫æ C√ÅC ID C·ª¶A B·∫†N V√ÄO ƒê√ÇY !!!
MODEL_FILE_ID = '16v3zUzOhPqnF6n3-80lYq7UcYRmej7RJ' 
METADATA_FILE_ID = '1x_Zb0mO_rOjhep71QveJcVleBLO2HCEs'

# --- 2. H√†m T·∫£i t·ªáp chung ---
def download_file_from_gdrive(file_id, dest_path):
    if not os.path.exists(dest_path):
        with st.spinner(f"ƒêang t·∫£i t√†i nguy√™n: {dest_path} (l·∫ßn ƒë·∫ßu ti√™n)..."):
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, dest_path, quiet=False)
    return dest_path

# --- 3. H√†m T·∫£i Model v√† D·ªØ li·ªáu ---
@st.cache_resource
def load_model(file_id, dest_path):
    # D√πng cache_resource ƒë·ªÉ t·∫£i model 1 L·∫¶N DUY NH·∫§T
    try:
        model_path = download_file_from_gdrive(file_id, dest_path)
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i m√¥ h√¨nh: {e}")
        return None

@st.cache_data
def load_metadata(file_id, dest_path):
    # D√πng cache_data ƒë·ªÉ t·∫£i metadata 1 L·∫¶N DUY NH·∫§T
    try:
        metadata_path = download_file_from_gdrive(file_id, dest_path)
        df = pd.read_csv(metadata_path)
        return df
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i metadata: {e}")
        return pd.DataFrame()

# --- 4. H√†m l·∫•y h√¨nh ·∫£nh (Kh√¥ng ƒë·ªïi) ---
def get_first_image_url(images_str):
    placeholder_image = "https://cdn.freelogovectors.net/wp-content/uploads/2022/10/foodcom-logo-freelogovectors.net_-400x144.png" 
    if not isinstance(images_str, str) or pd.isna(images_str):
        return placeholder_image
    try:
        evaluated_data = ast.literal_eval(images_str)
        if isinstance(evaluated_data, list):
            if len(evaluated_data) > 0:
                return evaluated_data[0]
            else:
                return placeholder_image
        if isinstance(evaluated_data, str):
            if evaluated_data.startswith('http'):
                return evaluated_data
            else:
                return placeholder_image
    except (ValueError, SyntaxError):
        if images_str.startswith('http'):
            return images_str
    return placeholder_image

# --- 5. H√ÄM T√çNH TO√ÅN (ƒê√É S·ª¨A L·ªñI CACHE) ---
# H√†m n√†y s·∫Ω s·ª≠ d·ª•ng c√°c bi·∫øn 'model' v√† 'all_recipe_ids_tuple'
# ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b√™n ngo√†i
@st.cache_data
def get_sampled_predictions(user_id, sample_size= 100): # <-- CH·ªà NH·∫¨N user_id
    """
    T√≠nh to√°n d·ª± ƒëo√°n tr√™n m·ªôt M·∫™U NG·∫™U NHI√äN.
    H√†m n√†y ch·ªâ ph·ª• thu·ªôc v√†o user_id n√™n cache R·∫§T NHANH.
    """
    
    # 1. L·∫•y m·∫´u ng·∫´u nhi√™n
    # (all_recipe_ids_tuple l√† bi·∫øn to√†n c·ª•c)
    if len(all_recipe_ids_tuple) > sample_size:
        sampled_ids = random.sample(all_recipe_ids_tuple, sample_size)
    else:
        sampled_ids = all_recipe_ids_tuple

    # 2. Ch·ªâ d·ª± ƒëo√°n tr√™n M·∫™U ƒë√£ l·∫•y
    # (model l√† bi·∫øn to√†n c·ª•c)
    predictions = []
    for recipe_id in sampled_ids:
        pred = model.predict(uid=user_id, iid=recipe_id)
        predictions.append((recipe_id, pred.est))
        
    # 3. S·∫Øp x·∫øp danh s√°ch
    predictions.sort(key=lambda x: x[1], reverse=True)
    return predictions

# --- 6. X√¢y d·ª±ng giao di·ªán Streamlit ---
st.set_page_config(layout="wide")
st.title("H·ªá th·ªëng G·ª£i √Ω M√≥n ƒÉn üç≤ üç≥ üç∞")

# --- N·∫†P C√ÅC BI·∫æN "TO√ÄN C·ª§C" ---
# C√°c bi·∫øn n√†y ƒë∆∞·ª£c n·∫°p 1 l·∫ßn duy nh·∫•t v√† kh√¥ng b·ªã cache l·∫°i
model = load_model(MODEL_FILE_ID, MODEL_FILE_PATH)
metadata_df = load_metadata(METADATA_FILE_ID, METADATA_FILE_PATH)

if model and not metadata_df.empty:
    st.header("T√¨m m√≥n ƒÉn cho b·∫°n")
    
    # T·∫°o c√°c bi·∫øn "to√†n c·ª•c" 1 l·∫ßn
    all_recipe_ids_tuple = tuple(metadata_df['RecipeId'].unique())
    metadata_df = metadata_df.set_index('RecipeId')
    
    # --- WIDGETS ---
    user_id_input = st.number_input(
        "Nh·∫≠p User ID c·ªßa b·∫°n:", 
        min_value=1, 
        value=1535,
        step=1,
        help="H√£y nh·∫≠p m·ªôt User ID (v√≠ d·ª•: 1535, 2046, 5201...)"
    )
    
    num_recs = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω:", min_value=5, max_value=20, value=10)

    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
    with st.spinner("ƒêang t√≠nh to√°n g·ª£i √Ω..."):
        
        # 1. G·ªçi h√†m L·∫§Y M·∫™U (ƒë√£ cache)
        # B√ÇY GI·ªú CH·ªà C·∫¶N TRUY·ªÄN user_id
        all_preds = get_sampled_predictions(user_id_input) 
        
        # 2. L·∫•y Top N
        top_n_preds = all_preds[:num_recs]
        
        # 3. L·∫•y Recipe IDs
        top_n_ids = [recipe_id for recipe_id, score in top_n_preds]
        
        # 4. Tra c·ª©u metadata
        valid_top_n_ids = [idx for idx in top_n_ids if idx in metadata_df.index]
        if valid_top_n_ids:
            recs_df = metadata_df.loc[valid_top_n_ids].copy()
            
            st.subheader(f"G·ª£i √Ω cho User {user_id_input}:")
            
            cols = st.columns(2)
            col_idx = 0
            
            for index, row in recs_df.iterrows():
                with cols[col_idx]:
                    image_url = get_first_image_url(row['Images'])
                    st.image(image_url, caption=f"Recipe ID: {row.name}", use_container_width=True)
                    st.subheader(row['Name'])
                    if 'Description' in row and pd.notna(row['Description']):
                         st.markdown(f"**M√¥ t·∫£:** {row['Description'][:150]}...")
                    st.divider()
                
                col_idx = (col_idx + 1) % 2
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y g·ª£i √Ω n√†o. (C√≥ th·ªÉ do l·ªói l·∫•y m·∫´u ho·∫∑c ID kh√¥ng c√≥ trong metadata)")
else:
    st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh ho·∫∑c d·ªØ li·ªáu t·ª´ Google Drive. Vui l√≤ng ki·ªÉm tra l·∫°i File IDs.")
