import streamlit as st
import pandas as pd
import pickle
import os
import ast
import gdown
import random 
import re 
from surprise import SVD

# --- 1. ƒê·ªãnh nghƒ©a T√™n t·ªáp v√† File IDs ---
MODEL_FILE_PATH = 'svd_model.pkl' 
METADATA_FILE_PATH = 'recipes_metadata.csv' 
SIMILARITY_FILE_PATH = 'item_similarity.pkl'
ID_MAP_TO_INNER_PATH = 'recipe_id_to_inner_id.pkl'
ID_MAP_TO_RECIPE_PATH = 'inner_id_to_recipe_id.pkl'

# !!! THAY TH·∫æ C√ÅC ID C·ª¶A B·∫†N V√ÄO ƒê√ÇY !!!
MODEL_FILE_ID = '1mSWLAjm2Ho6Aox61PrIQJUgNyJObKSbu' 
METADATA_FILE_ID = '1jCm7OruZnwkkd5GRU42dycNcQdGOKNRv'
# --- TH√äM ID C·ª¶A 3 T·ªÜP M·ªöI B·∫†N V·ª™A T·∫¢I L√äN ---
SIMILARITY_FILE_ID = '1fZet8_t6XGIr_xPkivSHOi21kNbg4RnU'
ID_MAP_TO_INNER_ID = '1QPExL4F4ccoAGqZiVnZjhvk6BHWR4hry'
ID_MAP_TO_RECIPE_ID = '1wEpHK4vUKQ7YvY1OWKd65xQTfD8oJgX6'


# --- 2. H√†m T·∫£i t·ªáp chung ---
def download_file_from_gdrive(file_id, dest_path):
    if not os.path.exists(dest_path):
        with st.spinner(f"ƒêang t·∫£i t√†i nguy√™n: {dest_path} (l·∫ßn ƒë·∫ßu ti√™n)..."):
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, dest_path, quiet=False)
    return dest_path

# --- 3. H√†m T·∫£i Model v√† D·ªØ li·ªáu ---
@st.cache_resource
def load_model(file_id, dest_path):
    try:
        model_path = download_file_from_gdrive(file_id, dest_path)
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i m√¥ h√¨nh: {e}")
        return None

@st.cache_data
def load_metadata(file_id, dest_path):
    try:
        metadata_path = download_file_from_gdrive(file_id, dest_path)
        df = pd.read_csv(metadata_path)
        return df
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i metadata: {e}")
        return pd.DataFrame()

@st.cache_resource
def load_pickle_file(file_id, dest_path):
    try:
        file_path = download_file_from_gdrive(file_id, dest_path)
        with open(file_path, 'rb') as f:
            data = pickle.load(f)
        return data
    except Exception as e:
        st.error(f"L·ªñI khi t·∫£i t·ªáp {dest_path}: {e}")
        return None

# --- 4. H√ÄM L·∫§Y H√åNH ·∫¢NH (Kh√¥ng ƒë·ªïi) ---
def get_first_image_url(images_str):
    placeholder_image = "https://cdn.freelogovectors.net/wp-content/uploads/2022/10/foodcom-logo-freelogovectors.net_-400x144.png"
    if not isinstance(images_str, str) or pd.isna(images_str):
        return placeholder_image
    match = re.search(r'"(https://[^"]+)"', images_str)
    if match:
        return match.group(1)
    else:
        if images_str.startswith('http'):
            return images_str
    return placeholder_image

# --- 5. H√ÄM L√ÄM S·∫†CH TEXT (Kh√¥ng ƒë·ªïi) ---
def format_c_string(text_str, as_list=False):
    placeholder = "Kh√¥ng c√≥ th√¥ng tin"
    if not isinstance(text_str, str) or pd.isna(text_str):
        return placeholder if not as_list else []
    matches = re.findall(r'"([^"]+)"', text_str)
    if matches:
        if as_list:
            return matches 
        else:
            return ", ".join(matches) 
    else:
        return text_str if not as_list else [text_str]

# --- 6. H√ÄM T√çNH TO√ÅN (Cho Tab 2) ---
def get_all_predictions(user_id):
    all_ids = all_recipe_ids_tuple
    predictions = []
    for recipe_id in all_ids:
        pred = model.predict(uid=user_id, iid=recipe_id)
        predictions.append((recipe_id, pred.est))
    predictions.sort(key=lambda x: x[1], reverse=True)
    return predictions

# --- H√ÄM T√çNH TO√ÅN (Cho Tab 3) ---
def get_similar_items(recipe_id, num_recs=9):
    try:
        target_inner_id = id_map_to_inner[recipe_id]
        sim_scores = list(enumerate(similarity_matrix[target_inner_id]))
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
        top_inner_ids = [i[0] for i in sim_scores[1:num_recs+1]]
        top_recipe_ids = [id_map_to_recipe[inner_id] for inner_id in top_inner_ids]
        return top_recipe_ids
    except KeyError:
        return []
    except Exception as e:
        print(e)
        return []

# --- H√ÄM M·ªöI: HI·ªÇN TH·ªä CHI TI·∫æT ---
def build_detail_page(metadata_df):
    recipe_id = st.session_state.detail_recipe_id
    recipe_data = metadata_df[metadata_df['RecipeId'] == recipe_id].iloc[0]
    
    # N√∫t Quay l·∫°i
    if st.button("‚¨ÖÔ∏è Quay l·∫°i"):
        st.session_state.detail_recipe_id = None
        # Kh√¥ng c·∫ßn set active_tab, v√¨ n√≥ ƒë√£ ƒë∆∞·ª£c l∆∞u
        st.rerun()
    
    # B·ªë c·ª•c trang chi ti·∫øt
    img_col, info_col = st.columns([1, 2])
    with img_col:
        st.image(get_first_image_url(recipe_data.get('Images')), use_container_width=True)
    with info_col:
        st.subheader(recipe_data.get('Name', 'N/A'))
        st.markdown(f"**ID:** {recipe_data.get('RecipeId', 'N/A')}")
        st.markdown(f"**T√°c gi·∫£:** {recipe_data.get('AuthorName', 'N/A')}")
        st.markdown(f"**Danh m·ª•c:** {recipe_data.get('RecipeCategory', 'N/A')}")
        st.markdown(f"**Ng√†y ƒëƒÉng:** {recipe_data.get('DatePublished', 'N/A')}")
        st.markdown("---")
        st.markdown(f"**Th·ªùi gian chu·∫©n b·ªã:** {recipe_data.get('PrepTime', 'N/A')}")
        st.markdown(f"**Th·ªùi gian n·∫•u:** {recipe_data.get('CookTime', 'N/A')}")
        st.markdown(f"**T·ªïng th·ªùi gian:** {recipe_data.get('TotalTime', 'N/A')}")
        st.markdown("---")
        st.markdown(f"**ƒê√°nh gi√°:** {recipe_data.get('AggregatedRating', 'N/A')} / 5.0 ({recipe_data.get('ReviewCount', 0)} l∆∞·ª£t)")
        st.markdown("---")
        st.markdown(f"**Calories:** {recipe_data.get('Calories', 'N/A')}")
        st.markdown(f"**Ch·∫•t b√©o (Fat):** {recipe_data.get('FatContent', 'N/A')}")
        st.markdown(f"**Ch·∫•t b√©o b√£o h√≤a:** {recipe_data.get('SaturatedFatContent', 'N/A')}")
        st.markdown(f"**Cholesterol:** {recipe_data.get('CholesterolContent', 'N/A')}")
        st.markdown(f"**Sodium:** {recipe_data.get('SodiumContent', 'N/A')}")
        st.markdown(f"**Carbohydrate:** {recipe_data.get('CarbohydrateContent', 'N/A')}")
        st.markdown(f"**Ch·∫•t x∆° (Fiber):** {recipe_data.get('FiberContent', 'N/A')}")
        st.markdown(f"**ƒê∆∞·ªùng (Sugar):** {recipe_data.get('SugarContent', 'N/A')}")
        st.markdown(f"**Ch·∫•t ƒë·∫°m (Protein):** {recipe_data.get('ProteinContent', 'N/A')}")

    st.markdown("---")
    st.subheader("M√¥ t·∫£")
    st.write(recipe_data.get('Description', 'N/A'))
    st.subheader("Nguy√™n li·ªáu")
    ingredients_formatted = format_c_string(recipe_data.get('RecipeIngredientParts'), as_list=False)
    st.write(ingredients_formatted)
    st.subheader("H∆∞·ªõng d·∫´n")
    instructions_list = format_c_string(recipe_data.get('RecipeInstructions'), as_list=True)
    if isinstance(instructions_list, list):
        for i, step in enumerate(instructions_list):
            st.markdown(f"{i+1}. {step}")
    else:
        st.write(instructions_list)

# --- 7. H√ÄM X√ÇY D·ª∞NG TAB 1 (Duy·ªát m√≥n ƒÉn) ---
def build_browse_tab(metadata_df):
    
    # Callbacks
    def clear_all_filters():
        st.session_state.search_name = ""
        st.session_state.search_id = None
        st.session_state.search_category = "T·∫•t c·∫£"
        st.session_state.search_ingredients = ""
        st.session_state.page_number = 1
    
    def reset_page_number():
        if st.session_state.page_number > 1:
            st.session_state.page_number = 1

    # 7.2. Ch·∫ø ƒë·ªô DANH S√ÅCH (M·∫∑c ƒë·ªãnh)
    with st.expander("T√¨m ki·∫øm v√† L·ªçc", expanded=True):
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.text_input("T√¨m theo T√™n m√≥n ƒÉn", key="search_name", on_change=reset_page_number)
            st.text_input("L·ªçc theo Nguy√™n li·ªáu (ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y)", key="search_ingredients", on_change=reset_page_number)
        
        with col2:
            st.number_input("T√¨m theo ID m√≥n ƒÉn", value=None, step=1, placeholder="Nh·∫≠p ID...", key="search_id", on_change=reset_page_number)
            categories = ["T·∫•t c·∫£"] + sorted(list(metadata_df['RecipeCategory'].dropna().unique()))
            st.selectbox("L·ªçc theo Danh m·ª•c", options=categories, key="search_category", on_change=reset_page_number)
        
        with col3:
            st.write("X√≥a b·ªô l·ªçc:")
            st.button("X√≥a to√†n b·ªô", use_container_width=True, on_click=clear_all_filters)

    # √Åp d·ª•ng b·ªô l·ªçc
    filtered_df = metadata_df.copy()
    if st.session_state.search_name:
        filtered_df = filtered_df[filtered_df['Name'].str.contains(st.session_state.search_name, case=False, na=False)]
    if st.session_state.search_id is not None:
        filtered_df = filtered_df[filtered_df['RecipeId'] == st.session_state.search_id]
    if st.session_state.search_category != "T·∫•t c·∫£":
        filtered_df = filtered_df[filtered_df['RecipeCategory'] == st.session_state.search_category]
    if st.session_state.search_ingredients:
        ingredients_list = [ing.strip() for ing in st.session_state.search_ingredients.split(',') if ing.strip()]
        for ing in ingredients_list:
            filtered_df = filtered_df[filtered_df['RecipeIngredientParts'].str.contains(ing, case=False, na=False)]

    # Ph√¢n trang
    total_items = len(filtered_df)
    st.write(f"T√¨m th·∫•y **{total_items}** m√≥n ƒÉn ph√π h·ª£p.")
    
    if total_items > 0:
        ITEMS_PER_PAGE = 9 
        total_pages = max(1, (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE)
        
        page_col1, page_col2 = st.columns([1, 1])
        with page_col1:
            st.number_input("Trang", min_value=1, max_value=total_pages, step=1, key="page_number")
        with page_col2:
            st.write(f"T·ªïng s·ªë trang: {total_pages}")

        start_idx = (st.session_state.page_number - 1) * ITEMS_PER_PAGE
        end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)
        items_to_display = filtered_df.iloc[start_idx:end_idx]

        # 3 c·ªôt
        cols = st.columns(3)
        col_idx = 0
        
        for index, row in items_to_display.iterrows():
            with cols[col_idx]:
                image_url = get_first_image_url(row['Images'])
                st.image(image_url, caption=f"Recipe ID: {row['RecipeId']}", use_container_width=True)
                st.subheader(row['Name'])
                
                if st.button("Xem chi ti·∫øt", key=f"detail_{row['RecipeId']}"):
                    st.session_state.detail_recipe_id = row['RecipeId']
                    # KH√îNG C·∫¶N L∆ØU TAB V√å RADIO S·∫º T·ª∞ NH·ªö
                    st.rerun() 
                
                st.divider()
            
            col_idx = (col_idx + 1) % 3

# --- 8. H√ÄM X√ÇY D·ª∞NG TAB 2 (G·ª£i √Ω) ---
def build_predict_tab(metadata_df_indexed):
    
    st.header("T√¨m m√≥n ƒÉn cho b·∫°n")
    
    user_id_input = st.number_input(
        "Nh·∫≠p User ID c·ªßa b·∫°n:", 
        min_value=1, 
        value=1535,
        step=1,
        help="H√£y nh·∫≠p m·ªôt User ID (v√≠ d·ª•: 1535, 2046, 5201...)"
    )
    num_recs = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω:", min_value=3, max_value=21, value=9, step=3)

    if st.button("T√¨m ki·∫øm g·ª£i √Ω"):
        with st.spinner("ƒêang t√≠nh to√°n g·ª£i √Ω (tr√™n to√†n b·ªô d·ªØ li·ªáu)..."):
            all_preds = get_all_predictions(user_id_input) 
            st.session_state['all_predictions'] = all_preds
    
    if 'all_predictions' in st.session_state and st.session_state.all_predictions is not None:
        all_preds = st.session_state.all_predictions
        top_n_preds = all_preds[:num_recs]
        
        top_n_ids = [recipe_id for recipe_id, score in top_n_preds]
        
        valid_top_n_ids = [idx for idx in top_n_ids if idx in metadata_df_indexed.index]
        if valid_top_n_ids:
            recs_df = metadata_df_indexed.loc[valid_top_n_ids].copy()
            
            st.subheader(f"K·∫øt qu·∫£ g·ª£i √Ω:")
            
            # 3 c·ªôt
            cols = st.columns(3)
            col_idx = 0
            
            for index, row in recs_df.iterrows():
                with cols[col_idx]:
                    image_url = get_first_image_url(row['Images'])
                    st.image(image_url, caption=f"Recipe ID: {row.name}", use_container_width=True)
                    st.subheader(row['Name'])
                    
                    if st.button("Xem chi ti·∫øt", key=f"pred_detail_{row.name}"):
                        st.session_state.detail_recipe_id = row.name 
                        st.rerun()
                    
                    if 'Description' in row and pd.notna(row['Description']):
                         st.markdown(f"**M√¥ t·∫£:** {row['Description'][:150]}...")
                    st.divider()
                
                col_idx = (col_idx + 1) % 3
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y g·ª£i √Ω n√†o.")

# --- H√ÄM M·ªöI: X√ÇY D·ª∞NG TAB 3 (M√≥n ƒÉn t∆∞∆°ng t·ª±) ---
def build_similar_item_tab(metadata_df, metadata_df_indexed):
    
    st.header("T√¨m c√°c m√≥n ƒÉn t∆∞∆°ng t·ª±")
    
    # L·∫•y danh s√°ch t√™n m√≥n ƒÉn ƒë·ªÉ ch·ªçn
    all_names = sorted(list(metadata_df['Name'].dropna().unique()))
    name_options = ["(Ch·ªçn m·ªôt m√≥n ƒÉn)"] + all_names
    
    selected_name = st.selectbox("Ch·ªçn m·ªôt m√≥n ƒÉn b·∫°n th√≠ch:", options=name_options)
    
    if selected_name != "(Ch·ªçn m·ªôt m√≥n ƒÉn)":
        
        # T√¨m RecipeId t·ª´ t√™n
        try:
            selected_recipe_id = metadata_df[metadata_df['Name'] == selected_name].iloc[0]['RecipeId']
            st.write(f"ƒêang t√¨m c√°c m√≥n ƒÉn t∆∞∆°ng t·ª± nh∆∞: **{selected_name}** (ID: {selected_recipe_id})")

            # G·ªçi h√†m g·ª£i √Ω m·ªõi
            similar_recipe_ids = get_similar_items(selected_recipe_id, num_recs=9)
            
            if similar_recipe_ids:
                recs_df = metadata_df_indexed.loc[similar_recipe_ids].copy()
                
                st.subheader(f"C√°c m√≥n ƒÉn t∆∞∆°ng t·ª±:")
                
                # 3 c·ªôt
                cols = st.columns(3)
                col_idx = 0
                
                for index, row in recs_df.iterrows():
                    with cols[col_idx]:
                        image_url = get_first_image_url(row['Images'])
                        st.image(image_url, caption=f"Recipe ID: {row.name}", use_container_width=True)
                        st.subheader(row['Name'])
                        
                        if st.button("Xem chi ti·∫øt", key=f"sim_detail_{row.name}"):
                            st.session_state.detail_recipe_id = row.name
                            st.rerun()
                        
                        if 'Description' in row and pd.notna(row['Description']):
                             st.markdown(f"**M√¥ t·∫£:** {row['Description'][:150]}...")
                        st.divider()
                    
                    col_idx = (col_idx + 1) % 3
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y m√≥n ƒÉn t∆∞∆°ng t·ª± (c√≥ th·ªÉ m√≥n ƒÉn n√†y kh√¥ng c√≥ trong m√¥ h√¨nh hu·∫•n luy·ªán).")
                
        except IndexError:
            st.error("Kh√¥ng t√¨m th·∫•y ID cho m√≥n ƒÉn n√†y.")

# --- 9. CH·∫†Y ·ª®NG D·ª§NG CH√çNH ---
st.set_page_config(layout="wide")
st.title("H·ªá th·ªëng G·ª£i √Ω M√≥n ƒÉn üç≤ üç≥ üç∞")

# --- N·∫†P T·∫§T C·∫¢ D·ªÆ LI·ªÜU ---
model = load_model(MODEL_FILE_ID, MODEL_FILE_PATH)
metadata_df = load_metadata(METADATA_FILE_ID, METADATA_FILE_PATH)
similarity_matrix = load_pickle_file(SIMILARITY_FILE_ID, SIMILARITY_FILE_PATH)
id_map_to_inner = load_pickle_file(ID_MAP_TO_INNER_ID, ID_MAP_TO_INNER_PATH)
id_map_to_recipe = load_pickle_file(ID_MAP_TO_RECIPE_ID, ID_MAP_TO_RECIPE_PATH)

# Ki·ªÉm tra xem t·∫•t c·∫£ ƒë√£ ƒë∆∞·ª£c t·∫£i
if model and (not metadata_df.empty) and similarity_matrix is not None and id_map_to_inner and id_map_to_recipe:
    
    # Kh·ªüi t·∫°o session state
    if 'detail_recipe_id' not in st.session_state:
        st.session_state.detail_recipe_id = None
    if 'all_predictions' not in st.session_state:
        st.session_state.all_predictions = None
    if 'search_name' not in st.session_state:
        st.session_state.search_name = ""
    if 'search_id' not in st.session_state:
        st.session_state.search_id = None
    if 'search_category' not in st.session_state:
        st.session_state.search_category = "T·∫•t c·∫£"
    if 'search_ingredients' not in st.session_state:
        st.session_state.search_ingredients = ""
    if 'page_number' not in st.session_state:
        st.session_state.page_number = 1
    # <<< TH√äM M·ªöI T·∫†I ƒê√ÇY: L∆∞u tab ƒëang ho·∫°t ƒë·ªông
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = "Duy·ªát M√≥n ƒÇn" # Tab m·∫∑c ƒë·ªãnh
    
    # T·∫°o c√°c bi·∫øn to√†n c·ª•c
    all_recipe_ids_tuple = tuple(metadata_df['RecipeId'].unique())
    metadata_df_indexed = metadata_df.set_index('RecipeId')
    
    # --- LOGIC HI·ªÇN TH·ªä CH√çNH ---
    # N·∫øu ƒëang ·ªü ch·∫ø ƒë·ªô "Xem chi ti·∫øt", hi·ªÉn th·ªã trang chi ti·∫øt
    if st.session_state.detail_recipe_id is not None:
        build_detail_page(metadata_df)
    
    # Ng∆∞·ª£c l·∫°i, hi·ªÉn th·ªã "tabs" (d√πng radio)
    else:
        # <<< S·ª¨A L·ªñI T·∫†I ƒê√ÇY: D√πng st.radio ƒë·ªÉ m√¥ ph·ªèng tabs
        tab_list = ["Duy·ªát M√≥n ƒÇn", "G·ª£i √ù Cho B·∫°n", "T√¨m M√≥n T∆∞∆°ng T·ª±"]
        
        selected_tab = st.radio(
            "Navigation", 
            tab_list, 
            key="active_tab", # Li√™n k·∫øt v·ªõi session state
            horizontal=True,
            label_visibility="collapsed" # ·∫®n ch·ªØ "Navigation"
        )
        # <<< K·∫æT TH√öC S·ª¨A L·ªñI

        # D√πng if/elif ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng tab
        if selected_tab == "Duy·ªát M√≥n ƒÇn":
            build_browse_tab(metadata_df)
        elif selected_tab == "G·ª£i √ù Cho B·∫°n":
            build_predict_tab(metadata_df_indexed)
        elif selected_tab == "T√¨m M√≥n T∆∞∆°ng T·ª±":
            build_similar_item_tab(metadata_df, metadata_df_indexed)
        
else:
    st.error("ƒêang t·∫£i d·ªØ li·ªáu... Vui l√≤ng ki·ªÉm tra l·∫°i 5 File IDs trong app.py v√† ƒë·∫£m b·∫£o ƒë√£ th√™m 'scikit-learn' v√†o requirements.txt")
