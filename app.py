import streamlit as st
import pandas as pd
import pickle
import os
import ast
import gdown
import random # <-- THÃŠM THÆ¯ VIá»†N NÃ€Y
from surprise import SVD

# --- 1. Äá»‹nh nghÄ©a TÃªn tá»‡p vÃ  File IDs ---
MODEL_FILE_PATH = 'svd_model.pkl' 
METADATA_FILE_PATH = 'recipes_metadata.csv' 

# !!! THAY THáº¾ CÃC ID Cá»¦A Báº N VÃ€O ÄÃ‚Y !!!
MODEL_FILE_ID = '16v3zUzOhPqnF6n3-80lYq7UcYRmej7RJ' 
METADATA_FILE_ID = '1x_Zb0mO_rOjhep71QveJcVleBLO2HCEs'

# --- 2. HÃ m Táº£i tá»‡p chung ---
def download_file_from_gdrive(file_id, dest_path):
    if not os.path.exists(dest_path):
        with st.spinner(f"Äang táº£i tÃ i nguyÃªn: {dest_path} (láº§n Ä‘áº§u tiÃªn)..."):
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, dest_path, quiet=False)
    return dest_path

# --- 3. HÃ m Táº£i Model vÃ  Dá»¯ liá»‡u ---
@st.cache_resource
def load_model(file_id, dest_path):
    try:
        model_path = download_file_from_gdrive(file_id, dest_path)
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model
    except Exception as e:
        st.error(f"Lá»–I khi táº£i mÃ´ hÃ¬nh: {e}")
        return None

@st.cache_data
def load_metadata(file_id, dest_path):
    try:
        metadata_path = download_file_from_gdrive(file_id, dest_path)
        df = pd.read_csv(metadata_path)
        return df
    except Exception as e:
        st.error(f"Lá»–I khi táº£i metadata: {e}")
        return pd.DataFrame()

# --- 4. HÃ m láº¥y hÃ¬nh áº£nh (KhÃ´ng Ä‘á»•i) ---
def get_first_image_url(images_str):
    placeholder_image = "KhÃ´ng cÃ³ áº£nh" 
    if not isinstance(images_str, str) or pd.isna(images_str):
        return placeholder_image
    try:
        evaluated_data = ast.literal_eval(images_str)
        if isinstance(evaluated_data, list):
            if len(evaluated_data) > 0:
                return evaluated_data[0]
            else:
                return placeholder_image
        if isinstance(evaluated_data, str):
            if evaluated_data.startswith('http'):
                return evaluated_data
            else:
                return placeholder_image
    except (ValueError, SyntaxError):
        if images_str.startswith('http'):
            return images_str
    return placeholder_image

# --- 5. HÃ€M TÃNH TOÃN (ÄÃƒ Sá»¬A Lá»–I) ---
@st.cache_data
def get_sampled_predictions(user_id, _model, all_recipe_ids, sample_size=20000):
    """
    TÃ­nh toÃ¡n dá»± Ä‘oÃ¡n trÃªn má»™t MáºªU NGáºªU NHIÃŠN Ä‘á»ƒ trÃ¡nh crash RAM.
    """
    
    # 1. Láº¥y máº«u ngáº«u nhiÃªn
    if len(all_recipe_ids) > sample_size:
        # Chuyá»ƒn Ä‘á»•i sang list Ä‘á»ƒ random.sample cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng
        sampled_ids = random.sample(list(all_recipe_ids), sample_size)
    else:
        sampled_ids = all_recipe_ids

    # 2. Chá»‰ dá»± Ä‘oÃ¡n trÃªn MáºªU Ä‘Ã£ láº¥y
    predictions = []
    for recipe_id in sampled_ids:
        pred = _model.predict(uid=user_id, iid=recipe_id)
        predictions.append((recipe_id, pred.est))
        
    # 3. Sáº¯p xáº¿p danh sÃ¡ch (nhá» hÆ¡n nhiá»u)
    predictions.sort(key=lambda x: x[1], reverse=True)
    return predictions

# --- 6. XÃ¢y dá»±ng giao diá»‡n Streamlit ---
st.set_page_config(layout="wide")
st.title("Há»‡ thá»‘ng Gá»£i Ã½ MÃ³n Äƒn ğŸ² ğŸ³ ğŸ°")

model = load_model(MODEL_FILE_ID, MODEL_FILE_PATH)
metadata_df = load_metadata(METADATA_FILE_ID, METADATA_FILE_PATH)

if model and not metadata_df.empty:
    st.header("TÃ¬m mÃ³n Äƒn cho báº¡n")
    
    # Láº¥y danh sÃ¡ch ID mÃ³n Äƒn (chá»‰ cháº¡y 1 láº§n)
    all_recipe_ids_list = metadata_df['RecipeId'].unique()
    
    # Äáº·t index sau (Ä‘á»ƒ tra cá»©u nhanh)
    metadata_df = metadata_df.set_index('RecipeId')
    
    user_id_input = st.number_input(
        "Nháº­p User ID cá»§a báº¡n:", 
        min_value=1, 
        value=1535,
        step=1,
        help="HÃ£y nháº­p má»™t User ID (vÃ­ dá»¥: 1535, 2046, 5201...)"
    )
    
    num_recs = st.slider("Sá»‘ lÆ°á»£ng gá»£i Ã½:", min_value=5, max_value=20, value=10)

    # --- Sá»¬A Lá»–I Táº I ÄÃ‚Y ---
    with st.spinner("Äang tÃ­nh toÃ¡n gá»£i Ã½..."):
        
        # 1. Gá»i hÃ m Láº¤Y MáºªU (Ä‘Ã£ cache, siÃªu nhanh)
        all_preds = get_sampled_predictions(user_id_input, model, all_recipe_ids_list)
        
        # 2. Láº¥y Top N
        top_n_preds = all_preds[:num_recs]
        
        # 3. Láº¥y Recipe IDs
        top_n_ids = [recipe_id for recipe_id, score in top_n_preds]
        
        # 4. Tra cá»©u metadata
        recs_df = metadata_df.loc[top_n_ids].copy()
        
        st.subheader(f"Gá»£i Ã½ cho User {user_id_input}:")
        
        cols = st.columns(2)
        col_idx = 0
        
        for index, row in recs_df.iterrows():
            with cols[col_idx]:
                image_url = get_first_image_url(row['Images'])
                st.image(image_url, caption=f"Recipe ID: {row.name}", use_column_width=True)
                st.subheader(row['Name'])
                if 'Description' in row and pd.notna(row['Description']):
                     st.markdown(f"**MÃ´ táº£:** {row['Description'][:150]}...")
                st.divider()
            
            col_idx = (col_idx + 1) % 2
else:
    st.error("KhÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh hoáº·c dá»¯ liá»‡u tá»« Google Drive. Vui lÃ²ng kiá»ƒm tra láº¡i File IDs.")
